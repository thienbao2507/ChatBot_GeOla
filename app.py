from openai import OpenAI
import gradio as gr
import os
from dotenv import load_dotenv
from newspaper import Article
import requests
from bs4 import BeautifulSoup
import fitz  # x·ª≠ l√Ω PDF

# L∆∞u n·ªôi dung PDF
pdf_context = {"content": ""}

# T·∫£i PDF
def upload_pdf(file):
    text = ""
    try:
        doc = fitz.open(file.name)
        for page in doc:
            text += page.get_text()
        pdf_context["content"] = text
        return "‚úÖ ƒê√£ t·∫£i v√† ƒë·ªçc n·ªôi dung PDF th√†nh c√¥ng!"
    except Exception as e:
        return f"‚ùå L·ªói ƒë·ªçc PDF: {e}"

# T√¨m ki·∫øm tin t·ª©c
def is_news_query(text):
    keywords = ["s·ª± ki·ªán", "tin t·ª©c", "th·ªùi s·ª±", "m·ªõi nh·∫•t", "tin n√≥ng"]
    return any(kw in text.lower() for kw in keywords)

def get_latest_news():
    try:
        url = "https://vnexpress.net/rss/tin-moi-nhat.rss"
        resp = requests.get(url)
        soup = BeautifulSoup(resp.content, features="xml")
        items = soup.findAll("item")[:3]
        news = "\n\n".join(f"{i+1}. {item.title.text}" for i, item in enumerate(items))
        return news
    except Exception as e:
        return f"Kh√¥ng l·∫•y ƒë∆∞·ª£c tin t·ª©c m·ªõi: {e}"

# Tr√≠ch xu·∫•t b√†i b√°o
def is_url(text):
    return text.startswith("http://") or text.startswith("https://")

def summarize_article(url):
    try:
        article = Article(url)
        article.download()
        article.parse()
        return article.text
    except:
        return "Kh√¥ng th·ªÉ tr√≠ch xu·∫•t n·ªôi dung t·ª´ ƒë∆∞·ªùng link n√†y."

# Load KEY
load_dotenv()
client = OpenAI(
    api_key=os.getenv("GEMINI_API_KEY"),
    base_url="https://generativelanguage.googleapis.com/v1beta/openai/"
)

# H√†m ch√≠nh
def chat_with_gemini(message, history):
    # 1. H·ªèi s·ª± ki·ªán
    if is_news_query(message):
        raw_news = get_latest_news()
        prompt = f"H√£y t√≥m t·∫Øt v√† ph√¢n t√≠ch c√°c s·ª± ki·ªán sau b·∫±ng ti·∫øng Vi·ªát:\n\n{raw_news}"
        response = client.chat.completions.create(
            model="gemini-2.0-flash",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content

    # 2. Link b√†i b√°o
    if is_url(message):
        article_text = summarize_article(message)
        if article_text.startswith("‚ùå"):
            return article_text
        prompt = f"T√≥m t·∫Øt b√†i b√°o sau b·∫±ng ti·∫øng Vi·ªát ng·∫Øn g·ªçn:\n\n{article_text}"
        response = client.chat.completions.create(
            model="gemini-2.0-flash",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content

    # 3. N·∫øu c√≥ PDF th√¨ k·∫øt h·ª£p v√†o prompt
    prompt = ""
    if pdf_context["content"]:
        prompt = f"D·ª±a v√†o t√†i li·ªáu sau, tr·∫£ l·ªùi c√¢u h·ªèi:\n\n{pdf_context['content']}\n\nC√¢u h·ªèi: {message}"
    else:
        prompt = message

    messages = [{"role": "system", "content": "B·∫°n l√† tr·ª£ l√Ω AI th√¢n thi·ªán."}]
    for user, bot in history:
        messages.append({"role": "user", "content": user})
        messages.append({"role": "assistant", "content": bot})
    messages.append({"role": "user", "content": prompt})

    stream = client.chat.completions.create(
        model="gemini-2.0-flash",
        messages=messages,
        stream=True
    )

    full_reply = ""
    for chunk in stream:
        if chunk.choices and chunk.choices[0].delta and chunk.choices[0].delta.content:
            full_reply += chunk.choices[0].delta.content
    return full_reply

# Giao di·ªán chatbot
with gr.Blocks() as app:
    gr.Markdown("ChatBot")
    pdf_upload = gr.File(label="üìÑ T·∫£i l√™n file PDF", file_types=[".pdf"])
    upload_status = gr.Textbox(label="Tr·∫°ng th√°i ƒë·ªçc file", interactive=False)
    chatbot = gr.ChatInterface(fn=chat_with_gemini)
    pdf_upload.change(fn=upload_pdf, inputs=pdf_upload, outputs=upload_status)

app.launch()
